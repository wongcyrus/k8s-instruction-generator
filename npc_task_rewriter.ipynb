{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Instruction Rewriter\n",
    "\n",
    "According the NPC background to rewrite in task instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_google_spreadsheet(spreadsheet_id):\n",
    "    url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv\"\n",
    "    response = requests.get(url, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        csv_str = response.content.decode(\"utf-8\")\n",
    "        f = StringIO(csv_str)\n",
    "        spreadsheet_data = []\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        next(reader, None)  # Skip the header row\n",
    "        for row in reader:\n",
    "            if len(row) < 4:\n",
    "                continue\n",
    "            name, age, gender, background = row[:4]\n",
    "            if not name:\n",
    "                continue\n",
    "            spreadsheet_data.append(\n",
    "                {\"name\": name, \"age\": age, \"gender\": gender, \"background\": background}\n",
    "            )\n",
    "        return spreadsheet_data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    gender: str \n",
    "    background: str\n",
    "\n",
    "npcs = get_google_spreadsheet(\"1VdQsc9qslvd-gGhydN5dEZEX6Q5uliBQqRguJyHBZM4\")\n",
    "main_character = npcs[0]\n",
    "if main_character['name'] != 'main_character':\n",
    "    raise ValueError(\"The main character's name is not 'main_character'\")\n",
    "main_character = Character(**main_character)\n",
    "\n",
    "npcs = npcs[1:]\n",
    "npcs.sort(key=lambda npc: npc['name'])\n",
    "npcs = [Character(**npc) for npc in npcs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "generator_model = ChatBedrock(\n",
    "    credentials_profile_name=\"genai\",\n",
    "    model_id=\"amazon.nova-micro-v1:0\",\n",
    "    model_kwargs=dict(temperature=0.5, topP=0.9),\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "validator_model = ChatBedrock(\n",
    "    credentials_profile_name=\"genai\",\n",
    "    model_id=\"amazon.nova-pro-v1:0\",\n",
    "    model_kwargs=dict(temperature=0, topP=0.1),\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "import re\n",
    "\n",
    "\n",
    "story_prompt = f\"\"\"\n",
    "## Task\n",
    "Your task is to rewrite the request from an NPC (non-player character) in a video game or interactive fiction story. \n",
    "The rewritten request should be more engaging, descriptive, and fitting for the given topic and character backgrounds.\n",
    "\n",
    "## Context\n",
    "\n",
    "### Topic\n",
    "\n",
    "{{topic}}\n",
    "\n",
    "### Character Backgrounds\n",
    "\n",
    "{{characters}}\n",
    "\n",
    "### Original NPC request\n",
    "\n",
    "{{raw_instruction}}\n",
    "\n",
    "To produce a high-quality rewritten request, please follow these guidelines:\n",
    "\n",
    "1. Read and understand the given topic, character backgrounds, and original NPC request.\n",
    "2. Identify the core intent or purpose behind the original request.\n",
    "3. Expand and embellish the request to make it more vivid, expressive, and aligned with the characters' personalities and backstories.\n",
    "4. Incorporate relevant details, descriptions, and context from the topic and character backgrounds.\n",
    "5. Maintain a consistent voice, tone, and style appropriate for the characters and story setting.\n",
    "6. Ensure the rewritten request flows naturally and avoids abrupt shifts or inconsistencies.\n",
    "7. Keep all placeholder \"{{{{{{{{...}}}}}}}}\" variables unchanged in the rewritten request.\n",
    "8. Keep the length of the rewritten request within a reasonable range based on the original request.\n",
    "9. Avoid introducing new characters, settings, or plot elements that are not present in the original request.\n",
    "10. Keep the Language in simple and easy to understand for the target audience in age group 13-18.\n",
    "\n",
    "Once you have carefully considered the context and guidelines, please provide your rewritten NPC request immediately without any preamble or additional text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "valid_conversation_prompt = f\"\"\"\n",
    "## Task\n",
    "Evaluate if a given dialogue between an NPC (non-player character) and Kube has the same task meaning as the original dialogue.\n",
    "\n",
    "## Instructions\n",
    "1. Review the original dialogue provided under the \"## Original Dialogue\" section.\n",
    "2. Review the rewritten dialogue provided under the \"## Rewritten Dialogue\" section.\n",
    "3. Determine if the task meaning in the rewritten dialogue is included in the original dialogue.\n",
    "4. If the task meaning is included, respond with \"Yes\" followed by your reasoning in parentheses.\n",
    "5. If the task meaning is not included, respond with \"No\" followed by your reasoning in parentheses.\n",
    "\n",
    "## Original Dialogue\n",
    "{{raw_instruction}}\n",
    "\n",
    "## Rewritten Dialogue\n",
    "{{dialogue}}\n",
    "\n",
    "## Response Format\n",
    "Provide your response immediately without any preamble or additional information:\n",
    "Yes/No. (reasoning)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    main_character: Character\n",
    "    characters: list[Character]\n",
    "    raw_instruction: str\n",
    "    conversations: Annotated[list[Character], operator.add]\n",
    "\n",
    "\n",
    "class StoryState(TypedDict):\n",
    "    topic: str\n",
    "    main_character: Character\n",
    "    character: Character\n",
    "    raw_instruction: str\n",
    "    conversation: str\n",
    "\n",
    "\n",
    "class ConversationState(TypedDict):\n",
    "    conversations: list[str]\n",
    "\n",
    "\n",
    "def load_characters(state: OverallState) -> OverallState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_conversation(state: StoryState) -> StoryState:\n",
    "    def print_character(character: Character):\n",
    "        return f\"\"\"\n",
    "        Name: {character.name}\n",
    "        Age: {character.age}      \n",
    "        Background Story: {character.background}\n",
    "        Gender: {character.gender}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    main_character = print_character(state[\"main_character\"])\n",
    "    character = print_character(state[\"character\"])\n",
    "    character_str = \"(Main Character)\" + main_character + \"(NPC)\" + character\n",
    "    prompt = story_prompt.format(\n",
    "        topic=state[\"topic\"],\n",
    "        characters=character_str,\n",
    "        raw_instruction=state[\"raw_instruction\"],\n",
    "    )\n",
    "    # print(prompt)\n",
    "    response = generator_model.invoke(prompt)\n",
    "    conversation = response.content\n",
    "    conversation = response.content.replace(\"\\n\\n\", \"\\n\")\n",
    "\n",
    "    # print(\"\\n\\nGenerated conversation:\\n\\n\")\n",
    "    # print(conversation)\n",
    "    # print(\"\\n\\n\")\n",
    "\n",
    "    return {\"conversation\": conversation}\n",
    "\n",
    "\n",
    "def continue_to_conversation(state: OverallState) -> List[Send]:\n",
    "    # We will return a list of `Send` objects\n",
    "    # Each `Send` object consists of the name of a node in the graph\n",
    "    # as well as the state to send to that node\n",
    "    return [\n",
    "        Send(\n",
    "            \"generate_conversation_subgraph\",\n",
    "            {\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"main_character\": state[\"main_character\"],\n",
    "                \"character\": s,\n",
    "                \"raw_instruction\": state[\"raw_instruction\"],\n",
    "                \"conversation\": \"\",\n",
    "            },\n",
    "        )\n",
    "        for s in state[\"characters\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def valid_conversation(state: StoryState) -> ConversationState:\n",
    "    # print(state)\n",
    "    return {\"conversations\": [state[\"conversation\"]]}\n",
    "\n",
    "\n",
    "def normalize_placeholders(text: str) -> str:\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"\\{\\{\\s*([^}]+?)\\s*\\}\\}\", r\"{{\\1}}\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def check_conversation_edge(\n",
    "    state: StoryState,\n",
    ") -> Literal[\"generate_conversation\", \"valid_conversation\"]:\n",
    "    dialogue = state[\"conversation\"]\n",
    "    raw_instruction = state[\"raw_instruction\"]\n",
    "    prompt = valid_conversation_prompt.format(\n",
    "        dialogue=dialogue, raw_instruction=raw_instruction\n",
    "    )\n",
    "\n",
    "    raw_norm = normalize_placeholders(state[\"raw_instruction\"])\n",
    "    conv_norm = normalize_placeholders(dialogue)\n",
    "    raw_ph = set(re.findall(r\"\\{\\{[^}]+\\}\\}\", raw_norm))\n",
    "    conv_ph = set(re.findall(r\"\\{\\{[^}]+\\}\\}\", conv_norm))\n",
    "    if raw_ph != conv_ph:\n",
    "        # print(\"Placeholders mismatch!\")\n",
    "        return \"generate_conversation\"\n",
    "\n",
    "    response = validator_model.invoke(prompt)\n",
    "    # print(response.content)\n",
    "    if \"Yes\" in response.content:\n",
    "        return \"valid_conversation\"\n",
    "    return \"generate_conversation\"\n",
    "\n",
    "\n",
    "def all_stories(state: OverallState) -> OverallState:\n",
    "    return state\n",
    "\n",
    "\n",
    "generate_conversation_subgraph_builder = StateGraph(\n",
    "    state_schema=StoryState, output_schema=ConversationState\n",
    ")\n",
    "generate_conversation_subgraph_builder.add_node(\n",
    "    \"generate_conversation\", generate_conversation\n",
    ")\n",
    "generate_conversation_subgraph_builder.add_node(\n",
    "    \"valid_conversation\", valid_conversation\n",
    ")\n",
    "\n",
    "generate_conversation_subgraph_builder.add_edge(START, \"generate_conversation\")\n",
    "generate_conversation_subgraph_builder.add_conditional_edges(\n",
    "    \"generate_conversation\", check_conversation_edge\n",
    ")\n",
    "generate_conversation_subgraph_builder.add_edge(\"valid_conversation\", END)\n",
    "generate_conversation_subgraph = generate_conversation_subgraph_builder.compile()\n",
    "\n",
    "\n",
    "generate_conversation_graph_builder = StateGraph(OverallState)\n",
    "generate_conversation_graph_builder.add_node(\"load_characters\", load_characters)\n",
    "generate_conversation_graph_builder.add_node(\n",
    "    \"generate_conversation_subgraph\", generate_conversation_subgraph\n",
    ")\n",
    "generate_conversation_graph_builder.add_node(\"all_stories\", all_stories)\n",
    "\n",
    "generate_conversation_graph_builder.add_edge(START, \"load_characters\")\n",
    "\n",
    "generate_conversation_graph_builder.add_conditional_edges(\n",
    "    \"load_characters\",\n",
    "    continue_to_conversation,\n",
    "    [\"generate_conversation_subgraph\"],\n",
    ")\n",
    "generate_conversation_graph_builder.add_edge(\n",
    "    \"generate_conversation_subgraph\", \"all_stories\"\n",
    ")\n",
    "\n",
    "generate_conversation_graph_builder.add_edge(\"all_stories\", END)\n",
    "\n",
    "generate_conversation_graph = generate_conversation_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(generate_conversation_subgraph.get_graph(xray=True).draw_mermaid_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(generate_conversation_graph.get_graph(xray=True).draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from session import get_instruction_template, get_tasks\n",
    "\n",
    "\n",
    "output_dir = \"output/rerwrite/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "main_character.name = \"Kube\"\n",
    "characters = npcs\n",
    "\n",
    "game = \"game01\"\n",
    "tasks = get_tasks(game)\n",
    "\n",
    "for task in tasks:\n",
    "    raw_instruction = get_instruction_template(game, task)\n",
    "    result = None\n",
    "\n",
    "    task_folder = os.path.join(output_dir, game, task)\n",
    "\n",
    "    character_instructions = [\n",
    "        os.path.join(task_folder, character.name, \"instruction.md\")\n",
    "        for character in characters\n",
    "    ]\n",
    "\n",
    "    if all(os.path.exists(f) for f in character_instructions):\n",
    "        print(f\"Task {task} already completed\")\n",
    "        continue\n",
    "\n",
    "    for s in generate_conversation_graph.stream(\n",
    "        input={\n",
    "            \"topic\": \"Kubernetes Isekai (異世界)\",\n",
    "            \"main_character\": main_character,\n",
    "            \"characters\": characters,\n",
    "            \"raw_instruction\": raw_instruction,\n",
    "        },\n",
    "        config={\"max_concurrency\": 4},\n",
    "    ):\n",
    "        print(s)\n",
    "        result = s\n",
    "\n",
    "    conversations = result[\"all_stories\"][\"conversations\"]\n",
    "\n",
    "    for file_path, conversation in zip(character_instructions, conversations):\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
